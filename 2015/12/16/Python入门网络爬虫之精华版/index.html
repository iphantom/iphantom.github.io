<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Python入门网络爬虫之精华版 | Phantom</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Python学习网络爬虫主要分3个大的版块：抓取，分析，存储  
另外，比较常用的爬虫框架Scrapy，这里最后也详细介绍一下。    
首先列举一下本人总结的相关文章，这些覆盖了入门网络爬虫需要的基本概念和技巧：宁哥的小站-网络爬虫  

当我们在浏览器中输入一个url后回车，后台会发生什么？比如说你输入http://www.lining0806.com/，你就会看到宁哥的小站首页。
简单来说">
<meta property="og:type" content="article">
<meta property="og:title" content="Python入门网络爬虫之精华版">
<meta property="og:url" content="i90s.vip/2015/12/16/Python入门网络爬虫之精华版/index.html">
<meta property="og:site_name" content="Phantom">
<meta property="og:description" content="Python学习网络爬虫主要分3个大的版块：抓取，分析，存储  
另外，比较常用的爬虫框架Scrapy，这里最后也详细介绍一下。    
首先列举一下本人总结的相关文章，这些覆盖了入门网络爬虫需要的基本概念和技巧：宁哥的小站-网络爬虫  

当我们在浏览器中输入一个url后回车，后台会发生什么？比如说你输入http://www.lining0806.com/，你就会看到宁哥的小站首页。
简单来说">
<meta property="og:updated_time" content="2015-12-28T07:54:18.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python入门网络爬虫之精华版">
<meta name="twitter:description" content="Python学习网络爬虫主要分3个大的版块：抓取，分析，存储  
另外，比较常用的爬虫框架Scrapy，这里最后也详细介绍一下。    
首先列举一下本人总结的相关文章，这些覆盖了入门网络爬虫需要的基本概念和技巧：宁哥的小站-网络爬虫  

当我们在浏览器中输入一个url后回车，后台会发生什么？比如说你输入http://www.lining0806.com/，你就会看到宁哥的小站首页。
简单来说">
  
    <link rel="alternative" href="/atom.xml" title="Phantom" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/avatar.png">
  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
</head>
<body>
<script src="//cdn.bootcss.com/JQuery-Snowfall/1.7.4/snowfall.jquery.min.js"></script>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/img/avatar.png" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Phantom</a></h1>
		</hgroup>

		
		<p class="header-subtitle">是我的海</p>
		
		
		<form><input type="text" class="search" placeholder=" Search..."></form>
				


		
			<div id="switch-btn" class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						<li>友情链接</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div id="switch-area" class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives/">所有文章</a></li>
				        
							<li><a href="/tags/">标签云</a></li>
				        
							<li><a href="/about/">留言板</a></li>
				        
							<li><a href="/built/">建站记事</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<ul class="social">
							
								<li id="Email"><a class="Email" target="_blank" href="mailto:admin@chengong.me" title="Email"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="https://github.com/iphantom" title="GitHub"></a></li>
					        
								<li id="RSS"><a class="RSS" target="_blank" href="/atom.xml" title="RSS"></a></li>
					        
								<li id="LinkedIn"><a class="LinkedIn" target="_blank" href="https://cn.linkedin.com/in/gong-chen-805212a5" title="LinkedIn"></a></li>
					        
						</ul>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/CS/" style="font-size: 10px;">CS</a> <a href="/tags/Eclipse/" style="font-size: 10px;">Eclipse</a> <a href="/tags/Jmeter/" style="font-size: 15px;">Jmeter</a> <a href="/tags/Mac/" style="font-size: 15px;">Mac</a> <a href="/tags/Oracle/" style="font-size: 13.33px;">Oracle</a> <a href="/tags/Out-of-memory-error/" style="font-size: 10px;">Out of memory error</a> <a href="/tags/PyDev/" style="font-size: 10px;">PyDev</a> <a href="/tags/Python/" style="font-size: 13.33px;">Python</a> <a href="/tags/Robot-Framework/" style="font-size: 10px;">Robot Framework</a> <a href="/tags/SQL用法/" style="font-size: 10px;">SQL用法</a> <a href="/tags/duoshuo/" style="font-size: 10px;">duoshuo</a> <a href="/tags/excel/" style="font-size: 11.67px;">excel</a> <a href="/tags/github/" style="font-size: 10px;">github</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/hexo用法/" style="font-size: 10px;">hexo用法</a> <a href="/tags/makedown/" style="font-size: 10px;">makedown</a> <a href="/tags/namecheap/" style="font-size: 10px;">namecheap</a> <a href="/tags/oracle/" style="font-size: 10px;">oracle</a> <a href="/tags/python/" style="font-size: 18.33px;">python</a> <a href="/tags/sublime/" style="font-size: 10px;">sublime</a> <a href="/tags/ubuntu/" style="font-size: 10px;">ubuntu</a> <a href="/tags/使用指南/" style="font-size: 10px;">使用指南</a> <a href="/tags/华为/" style="font-size: 10px;">华为</a> <a href="/tags/博客/" style="font-size: 13.33px;">博客</a> <a href="/tags/字符编码/" style="font-size: 10px;">字符编码</a> <a href="/tags/安装方法/" style="font-size: 10px;">安装方法</a> <a href="/tags/小七/" style="font-size: 11.67px;">小七</a> <a href="/tags/心情/" style="font-size: 10px;">心情</a> <a href="/tags/性能测试/" style="font-size: 13.33px;">性能测试</a> <a href="/tags/感悟/" style="font-size: 16.67px;">感悟</a> <a href="/tags/感言/" style="font-size: 11.67px;">感言</a> <a href="/tags/投资/" style="font-size: 10px;">投资</a> <a href="/tags/教程/" style="font-size: 10px;">教程</a> <a href="/tags/正交/" style="font-size: 10px;">正交</a> <a href="/tags/正交实验/" style="font-size: 10px;">正交实验</a> <a href="/tags/正交表/" style="font-size: 10px;">正交表</a> <a href="/tags/求助/" style="font-size: 10px;">求助</a> <a href="/tags/测试分类/" style="font-size: 13.33px;">测试分类</a> <a href="/tags/爬虫/" style="font-size: 10px;">爬虫</a> <a href="/tags/生日/" style="font-size: 10px;">生日</a> <a href="/tags/矩阵/" style="font-size: 10px;">矩阵</a> <a href="/tags/研究生/" style="font-size: 10px;">研究生</a> <a href="/tags/离职/" style="font-size: 10px;">离职</a> <a href="/tags/纪念日/" style="font-size: 10px;">纪念日</a> <a href="/tags/线性代数/" style="font-size: 10px;">线性代数</a> <a href="/tags/结构体/" style="font-size: 11.67px;">结构体</a> <a href="/tags/编程修养/" style="font-size: 13.33px;">编程修养</a> <a href="/tags/自动化测试/" style="font-size: 10px;">自动化测试</a> <a href="/tags/转载/" style="font-size: 20px;">转载</a> <a href="/tags/链表/" style="font-size: 11.67px;">链表</a> <a href="/tags/问题/" style="font-size: 10px;">问题</a> <a href="/tags/随笔/" style="font-size: 10px;">随笔</a> <a href="/tags/需求分析/" style="font-size: 10px;">需求分析</a> <a href="/tags/面向对象/" style="font-size: 16.67px;">面向对象</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
			        
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
			        
			        </div>
				</section>
				

				
				
				<section class="switch-part switch-part4">
				
					<div id="js-aboutme">————对不起，不告诉你————</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">Phantom</a></h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<a href="/" class="profilepic">
				<img lazy-src="/img/avatar.png" class="js-avatar">
			</a>
			<hgroup>
			  <h1 class="header-author"><a href="/" title="回到主页">Phantom</a></h1>
			</hgroup>
			
			<p class="header-subtitle">是我的海</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives/">所有文章</a></li>
		        
					<li><a href="/tags/">标签云</a></li>
		        
					<li><a href="/about/">留言板</a></li>
		        
					<li><a href="/built/">建站记事</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
						<ul class="social">
							
								<li id="Email"><a class="Email" target="_blank" href="mailto:admin@chengong.me" title="Email"></a></li>
					        
								<li id="GitHub"><a class="GitHub" target="_blank" href="https://github.com/iphantom" title="GitHub"></a></li>
					        
								<li id="RSS"><a class="RSS" target="_blank" href="/atom.xml" title="RSS"></a></li>
					        
								<li id="LinkedIn"><a class="LinkedIn" target="_blank" href="https://cn.linkedin.com/in/gong-chen-805212a5" title="LinkedIn"></a></li>
					        
						</ul>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-Python入门网络爬虫之精华版" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/12/16/Python入门网络爬虫之精华版/" class="article-date">
  	<time datetime="2015-12-16T03:29:32.000Z" itemprop="datePublished">2015-12-16</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Python入门网络爬虫之精华版
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/软件笔记/">软件笔记</a>
	</div>


        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/教程/">教程</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/转载/">转载</a></li></ul>
	</div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <hr>
<p>Python学习网络爬虫主要分3个大的版块：<strong>抓取</strong>，<strong>分析</strong>，<strong>存储</strong>  </p>
<p>另外，比较常用的爬虫框架<a href="http://scrapy.org/" target="_blank" rel="external">Scrapy</a>，这里最后也详细介绍一下。    </p>
<p>首先列举一下本人总结的相关文章，这些覆盖了入门网络爬虫需要的基本概念和技巧：<a href="http://www.lining0806.com/category/spider/" target="_blank" rel="external">宁哥的小站-网络爬虫</a>  </p>
<hr>
<p>当我们在浏览器中输入一个url后回车，后台会发生什么？比如说你输入<a href="http://www.lining0806.com/" target="_blank" rel="external">http://www.lining0806.com/</a>，你就会看到宁哥的小站首页。</p>
<p>简单来说这段过程发生了以下四个步骤：<br><a id="more"></a></p>
<ul>
<li>查找域名对应的IP地址。</li>
<li>向IP对应的服务器发送请求。</li>
<li>服务器响应请求，发回网页内容。</li>
<li>浏览器解析网页内容。</li>
</ul>
<p>网络爬虫要做的，简单来说，就是实现浏览器的功能。通过指定url，直接返回给用户所需要的数据，而不需要一步步人工去操纵浏览器获取。</p>
<h2 id="抓取"><a href="#抓取" class="headerlink" title="抓取"></a>抓取</h2><p>这一步，你要明确要得到的内容是是什么？是HTML源码，还是Json格式的字符串等。  </p>
<h4 id="1-最基本的抓取"><a href="#1-最基本的抓取" class="headerlink" title="1. 最基本的抓取"></a>1. 最基本的抓取</h4><p>抓取大多数情况属于get请求，即直接从对方服务器上获取数据。  </p>
<p>首先，Python中自带urllib及urllib2这两个模块，基本上能满足一般的页面抓取。另外，<a href="https://github.com/kennethreitz/requests" target="_blank" rel="external">requests</a>也是非常有用的包，与此类似的，还有<a href="https://github.com/jcgregorio/httplib2" target="_blank" rel="external">httplib2</a>等等。    </p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Requests：</span><br><span class="line">	import requests</span><br><span class="line">	response = requests.<span class="built_in">get</span>(url)</span><br><span class="line">	<span class="built_in">content</span> = requests.<span class="built_in">get</span>(url).<span class="built_in">content</span></span><br><span class="line">	<span class="built_in">print</span> <span class="string">"response headers:"</span>, response.headers</span><br><span class="line">	<span class="built_in">print</span> <span class="string">"content:"</span>, <span class="built_in">content</span></span><br><span class="line">Urllib2：</span><br><span class="line">	import urllib2</span><br><span class="line">	response = urllib2.urlopen(url)</span><br><span class="line">	<span class="built_in">content</span> = urllib2.urlopen(url).<span class="built_in">read</span>()</span><br><span class="line">	<span class="built_in">print</span> <span class="string">"response headers:"</span>, response.headers</span><br><span class="line">	<span class="built_in">print</span> <span class="string">"content:"</span>, <span class="built_in">content</span></span><br><span class="line">Httplib2：</span><br><span class="line">	import httplib2</span><br><span class="line">	http = httplib2.Http()</span><br><span class="line">	response_headers, <span class="built_in">content</span> = http.request(url, 'GET')</span><br><span class="line">	<span class="built_in">print</span> <span class="string">"response headers:"</span>, response_headers</span><br><span class="line">	<span class="built_in">print</span> <span class="string">"content:"</span>, <span class="built_in">content</span></span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">此外，对于带有查询字段的url，<span class="built_in">get</span>请求一般会将来请求的数据附在url之后，以?分割url和传输数据，多个参数用&amp;连接。</span><br></pre></td></tr></table></figure>
<p>data = {‘data1’:’XXXXX’, ‘data2’:’XXXXX’}<br>Requests：data为dict，json<br>    import requests<br>    response = requests.get(url=url, params=data)<br>Urllib2：data为string<br>    import urllib, urllib2<br>    data = urllib.urlencode(data)<br>    full_url = url+’?’+data<br>    response = urllib2.urlopen(full_url)<br><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">相关参考：[网易新闻排行榜抓取回顾](http:<span class="regexp">//www</span>.lining0806.com/%E7%BD%91%E6%98%93%E6%96%B0%E9%97%BB%E6%8E%92%E8%A1%8C%E6%A6%9C%E6%8A%93%E5%8F%96%E5%9B%9E%E9%A1%BE/)</span><br><span class="line"></span><br><span class="line">参考项目：[网络爬虫之最基本的爬虫：爬取网易新闻排行榜](https:<span class="regexp">//github</span>.com/lining0806/NewsSpider)</span><br><span class="line"></span><br><span class="line"><span class="comment">### 2. 对于登陆情况的处理  </span></span><br><span class="line"></span><br><span class="line">**<span class="number">2.1</span> 使用表单登陆**  </span><br><span class="line"></span><br><span class="line">这种情况属于post请求，即先向服务器发送表单数据，服务器再将返回的cookie存入本地。</span><br></pre></td></tr></table></figure></p>
<p>data = {‘data1’:’XXXXX’, ‘data2’:’XXXXX’}<br>Requests：data为dict，json<br>    import requests<br>    response = requests.post(url=url, data=data)<br>Urllib2：data为string<br>    import urllib, urllib2<br>    data = urllib.urlencode(data)<br>    req = urllib2.Request(url=url, data=data)<br>    response = urllib2.urlopen(req)<br><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">*<span class="strong">*2.2 使用cookie登陆*</span>*  </span><br><span class="line"></span><br><span class="line">使用cookie登陆，服务器会认为你是一个已登陆的用户，所以就会返回给你一个已登陆的内容。因此，需要验证码的情况可以使用带验证码登陆的cookie解决。</span><br></pre></td></tr></table></figure></p>
<p>import requests<br>requests_session = requests.session()<br>response = requests_session.post(url=url_login, data=data)<br><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">若存在验证码，此时采用response = requests_session.post(url=url_login, <span class="class"><span class="keyword">data</span>=<span class="keyword">data</span>)是不行的，做法应该如下：</span></span><br></pre></td></tr></table></figure></p>
<p>response_captcha = requests_session.get(url=url_login, cookies=cookies)<br>response1 = requests.get(url_login) # 未登陆<br>response2 = requests_session.get(url_login) # 已登陆，因为之前拿到了Response Cookie！<br>response3 = requests_session.get(url_results) # 已登陆，因为之前拿到了Response Cookie！<br><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">相关参考：[网络爬虫-验证码登陆](http:<span class="regexp">//www</span>.lining0806.com/<span class="number">6</span>-%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB-%E9%AA%8C%E8%AF%81%E7%A0%81%E7%99%BB%E9%99%86/)  </span><br><span class="line"></span><br><span class="line">参考项目：[网络爬虫之用户名密码及验证码登陆：爬取知乎网站](https:<span class="regexp">//github</span>.com/lining0806/ZhihuSpider)  </span><br><span class="line"></span><br><span class="line"><span class="comment">### 3. 对于反爬虫机制的处理 </span></span><br><span class="line"></span><br><span class="line">**<span class="number">3.1</span> 使用代理** </span><br><span class="line"></span><br><span class="line">适用情况：限制IP地址情况，也可解决由于“频繁点击”而需要输入验证码登陆的情况。  </span><br><span class="line"></span><br><span class="line">这种情况最好的办法就是维护一个代理IP池，网上有很多免费的代理IP，良莠不齐，可以通过筛选找到能用的。对于“频繁点击”的情况，我们还可以通过限制爬虫访问网站的频率来避免被网站禁掉。</span><br></pre></td></tr></table></figure></p>
<p>proxies = {‘http’:’<a href="http://XX.XX.XX.XX:XXXX&#39;}" target="_blank" rel="external">http://XX.XX.XX.XX:XXXX&#39;}</a><br>Requests：<br>    import requests<br>    response = requests.get(url=url, proxies=proxies)<br>Urllib2：<br>    import urllib2<br>    proxy_support = urllib2.ProxyHandler(proxies)<br>    opener = urllib2.build_opener(proxy_support, urllib2.HTTPHandler)<br>    urllib2.install_opener(opener) # 安装opener，此后调用urlopen()时都会使用安装过的opener对象<br>    response = urllib2.urlopen(url)<br><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">**3.2 时间设置** </span></span><br><span class="line"></span><br><span class="line">适用情况：限制频率情况。 </span><br><span class="line"></span><br><span class="line">Requests，Urllib2都可以使用time库的<span class="built-in">sleep</span>()函数：</span><br></pre></td></tr></table></figure></p>
<p>import time<br>time.sleep(1)<br><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">**<span class="number">3.3</span> 伪装成浏览器，或者反“反盗链”**  </span><br><span class="line"></span><br><span class="line">有些网站会检查你是不是真的浏览器访问，还是机器自动访问的。这种情况，加上User<span class="attr">-Agent</span>，表明你是浏览器访问即可。有时还会检查是否带<span class="keyword">Referer</span>信息还会检查你的<span class="keyword">Referer</span>是否合法，一般再加上<span class="keyword">Referer</span>。</span><br></pre></td></tr></table></figure></p>
<p>headers = {‘User-Agent’:’XXXXX’} # 伪装成浏览器访问，适用于拒绝爬虫的网站<br>headers = {‘Referer’:’XXXXX’}<br>headers = {‘User-Agent’:’XXXXX’, ‘Referer’:’XXXXX’}<br>Requests：<br>    response = requests.get(url=url, headers=headers)<br>Urllib2：<br>    import urllib, urllib2<br>    req = urllib2.Request(url=url, headers=headers)<br>    response = urllib2.urlopen(req)<br><figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">### 4. 对于断线重连  </span></span><br><span class="line"></span><br><span class="line">不多说。</span><br></pre></td></tr></table></figure></p>
<p>def multi_session(session, <em>arg):<br>    while True:<br>        retryTimes = 20<br>    while retryTimes&gt;0:<br>        try:<br>            return session.post(</em>arg)<br>        except:<br>            print ‘.’,<br>            retryTimes -= 1<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">或者</span><br></pre></td></tr></table></figure></p>
<p>def multi_open(opener, <em>arg):<br>    while True:<br>        retryTimes = 20<br>    while retryTimes&gt;0:<br>        try:<br>            return opener.open(</em>arg)<br>        except:<br>            print ‘.’,<br>            retryTimes -= 1<br>```</p>
<p>这样我们就可以使用multi_session或multi_open对爬虫抓取的session或opener进行保持。    </p>
<h3 id="5-多进程抓取"><a href="#5-多进程抓取" class="headerlink" title="5. 多进程抓取"></a>5. 多进程抓取</h3><p>这里针对<a href="http://live.wallstreetcn.com/" target="_blank" rel="external">华尔街见闻</a>进行并行抓取的实验对比：<a href="https://github.com/lining0806/Spider_Python" target="_blank" rel="external">Python多进程抓取</a> 与 <a href="https://github.com/lining0806/Spider" target="_blank" rel="external">Java单线程和多线程抓取</a>  </p>
<p>相关参考：<a href="http://www.lining0806.com/%E5%85%B3%E4%BA%8Epython%E5%92%8Cjava%E7%9A%84%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/" target="_blank" rel="external">关于Python和Java的多进程多线程计算方法对比</a>  </p>
<h3 id="6-对于Ajax请求的处理"><a href="#6-对于Ajax请求的处理" class="headerlink" title="6. 对于Ajax请求的处理"></a>6. 对于Ajax请求的处理</h3><p>对于“加载更多”情况，使用Ajax来传输很多数据。</p>
<p>它的工作原理是：从网页的url加载网页的源代码之后，会在浏览器里执行JavaScript程序。这些程序会加载更多的内容，“填充”到网页里。这就是为什么如果你直接去爬网页本身的url，你会找不到页面的实际内容。  </p>
<p>这里，若使用Google Chrome分析”请求“对应的链接(方法：右键→审查元素→Network→清空，点击”加载更多“，出现对应的GET链接寻找Type为text/html的，点击，查看get参数或者复制Request URL)，循环过程。  </p>
<ul>
<li>如果“请求”之前有页面，依据上一步的网址进行分析推导第1页。以此类推，抓取抓Ajax地址的数据。  </li>
<li>对返回的json格式数据(str)进行正则匹配。json格式数据中，需从’\uxxxx’形式的unicode_escape编码转换成u’\uxxxx’的unicode编码。  </li>
</ul>
<h3 id="7-自动化测试工具Selenium"><a href="#7-自动化测试工具Selenium" class="headerlink" title="7. 自动化测试工具Selenium"></a>7. 自动化测试工具Selenium</h3><p>Selenium是一款自动化测试工具。它能实现操纵浏览器，包括字符填充、鼠标点击、获取元素、页面切换等一系列操作。总之，凡是浏览器能做的事，Selenium都能够做到。</p>
<p>这里列出在给定城市列表后，使用selenium来动态抓取<a href="http://flight.qunar.com/" target="_blank" rel="external">去哪儿网</a>的票价信息的代码。</p>
<p>参考项目：<a href="https://github.com/lining0806/QunarSpider" target="_blank" rel="external">网络爬虫之Selenium使用代理登陆：爬取去哪儿网站</a> </p>
<h3 id="8-验证码识别"><a href="#8-验证码识别" class="headerlink" title="8. 验证码识别"></a>8. 验证码识别</h3><p>对于网站有验证码的情况，我们有三种办法：  </p>
<ul>
<li>使用代理，更新IP。</li>
<li>使用cookie登陆。</li>
<li>验证码识别。</li>
</ul>
<p>使用代理和使用cookie登陆之前已经讲过，下面讲一下验证码识别。  </p>
<p>可以利用开源的Tesseract-OCR系统进行验证码图片的下载及识别，将识别的字符传到爬虫系统进行模拟登陆。如果不成功，可以再次更新验证码识别，直到成功为止。  </p>
<p>参考项目：<a href="https://github.com/lining0806/Captcha1" target="_blank" rel="external">Captcha1</a></p>
<p><strong>爬取有两个需要注意的问题：</strong></p>
<ul>
<li>如何监控一系列网站的更新情况，也就是说，如何进行增量式爬取？</li>
<li>对于海量数据，如何实现分布式爬取？</li>
</ul>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>抓取之后就是对抓取的内容进行分析，你需要什么内容，就从中提炼出相关的内容来。  </p>
<p>常见的分析工具有<a href="http://deerchao.net/tutorials/regex/regex.htm" target="_blank" rel="external">正则表达式</a>，<a href="http://www.crummy.com/software/BeautifulSoup/" target="_blank" rel="external">BeautifulSoup</a>，<a href="http://lxml.de/" target="_blank" rel="external">lxml</a>等等。  </p>
<h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h2><p>分析出我们需要的内容之后，接下来就是存储了。  </p>
<p>我们可以选择存入文本文件，也可以选择存入<a href="http://www.mysql.com/" target="_blank" rel="external">MySQL</a>或<a href="https://www.mongodb.org/" target="_blank" rel="external">MongoDB</a>数据库等。  </p>
<p><strong>存储有两个需要注意的问题：</strong></p>
<ul>
<li>如何进行网页去重？</li>
<li>内容以什么形式存储？</li>
</ul>
<h2 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy"></a>Scrapy</h2><p>Scrapy是一个基于Twisted的开源的Python爬虫框架，在工业中应用非常广泛。  </p>
<p>相关内容可以参考<a href="http://www.lining0806.com/%E5%9F%BA%E4%BA%8Escrapy%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E7%9A%84%E6%90%AD%E5%BB%BA/" target="_blank" rel="external">基于Scrapy网络爬虫的搭建</a>，同时给出这篇文章介绍的<a href="http://weixin.sogou.com/weixin" target="_blank" rel="external">微信搜索</a>爬取的项目代码，给大家作为学习参考。</p>
<p>参考项目：<a href="https://github.com/lining0806/WechatSearchProjects" target="_blank" rel="external">使用Scrapy或Requests递归抓取微信搜索结果</a></p>

      
    </div>
    
  </div>
  
    
<div class="copyright">
  <p><span>本文标题:</span><a href="/2015/12/16/Python入门网络爬虫之精华版/">Python入门网络爬虫之精华版</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 Phantom 的个人博客">Phantom</a></p>
  <p><span>发布时间:</span>2015年12月16日 - 11时29分</p>
  <p><span>最后更新:</span>2015年12月28日 - 15时54分</p>
  <p>
    <span>原始链接:</span><a class="post-url" href="/2015/12/16/Python入门网络爬虫之精华版/" title="Python入门网络爬虫之精华版">i90s.vip/2015/12/16/Python入门网络爬虫之精华版/</a>
    <span class="copy-path" data-clipboard-text="原文: i90s.vip/2015/12/16/Python入门网络爬虫之精华版/　　作者: Phantom" title="点击复制文章链接">
        <i class="fa fa-clipboard"></i>
    </span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" title="中国大陆 (CC BY-NC-SA 3.0 CN)">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。</p>
  <script src="/js/clipboard.min.js"></script>
  <script> var clipboard = new Clipboard('.copy-path'); </script>
</div>




<nav id="article-nav">
  
    <div id="article-nav-newer" class="article-nav-title">
      <a href="/2015/12/27/编程修养（1）/">
        编程修养（1）
      </a>
    </div>
  
  
    <div id="article-nav-older" class="article-nav-title">
      <a href="/2015/12/15/理解矩阵/">
        理解矩阵
      </a>
    </div>
  
</nav>

  
</article>

<!-- 默认显示文章目录，在文章---前输入toc: false关闭目录 -->
<!-- Show TOC and tocButton in default, Hide TOC via putting "toc: false" before "---" at [post].md -->
<div id="toc" class="toc-article">
<strong class="toc-title">文章目录</strong>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#抓取"><span class="toc-number">1.</span> <span class="toc-text">抓取</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-最基本的抓取"><span class="toc-number">1.0.1.</span> <span class="toc-text">1. 最基本的抓取</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-多进程抓取"><span class="toc-number">1.1.</span> <span class="toc-text">5. 多进程抓取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-对于Ajax请求的处理"><span class="toc-number">1.2.</span> <span class="toc-text">6. 对于Ajax请求的处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-自动化测试工具Selenium"><span class="toc-number">1.3.</span> <span class="toc-text">7. 自动化测试工具Selenium</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-验证码识别"><span class="toc-number">1.4.</span> <span class="toc-text">8. 验证码识别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#分析"><span class="toc-number">2.</span> <span class="toc-text">分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#存储"><span class="toc-number">3.</span> <span class="toc-text">存储</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy"><span class="toc-number">4.</span> <span class="toc-text">Scrapy</span></a></li></ol>
</div>
<style type="text/css">
  .left-col .switch-btn {
    display: none;
  }
  .left-col .switch-area {
    display: none;
  }
</style>

<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">
<script type="text/javascript">
  var toc_button= document.getElementById("tocButton");
  var toc_div= document.getElementById("toc");
  /* Show or hide toc when click on tocButton.
  通过点击设置的按钮显示或者隐藏文章目录.*/
  toc_button.onclick=function(){
  if(toc_div.style.display=="none"){
  toc_div.style.display="block";
  toc_button.value="隐藏目录";
  document.getElementById("switch-btn").style.display="none";
  document.getElementById("switch-area").style.display="none";
  }
  else{
  toc_div.style.display="none";
  toc_button.value="显示目录";
  document.getElementById("switch-btn").style.display="block";
  document.getElementById("switch-area").style.display="block";
  }
  }
</script>


<div class="share">
	<div class="bdsharebuttonbox">
	<a href="#" class="bds_more" data-cmd="more"></a>
	<a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
	<a href="#" class="bds_copy" data-cmd="copy" title="复制网址"></a>
	<a href="#" class="bds_mail" data-cmd="mail" title="通过邮件分享"></a>
	<a href="#" class="bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
	</div>
	<script>
	window._bd_share_config={
		"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
	</script>
</div>



  
  <div class="duoshuo" id="comments">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="Python入门网络爬虫之精华版" data-title="Python入门网络爬虫之精华版" data-url="i90s.vip/2015/12/16/Python入门网络爬虫之精华版/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"chengong"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://chengong.me/js/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>

  





    <style type="text/css">
    #scroll {
      display: none;
    }
    </style>
    <div class="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
    </div>


  
  
    
    <div  class="post-nav-button">
    <a href="/2015/12/27/编程修养（1）/" title="上一篇: 编程修养（1）">
    <i class="fa fa-angle-left"></i>
    </a>
    <a href="/2015/12/15/理解矩阵/" title="下一篇: 理解矩阵">
    <i class="fa fa-angle-right"></i>
    </a>
    </div>
  



    
        <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
        <script>
        var yiliaConfig = {
        fancybox: true,
        mathjax: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        open_in_new: false
        }
        </script>
     
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2016 Phantom
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的静态博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减双栏 Hexo 博客主题">Yelee</a> by MOxFIVE
        </div>
    </div>
    <div class="visit">
	<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1257065196'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s11.cnzz.com/z_stat.php%3Fid%3D1257065196%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));</script>
    </div>
  </div>
</footer>
    </div>
    

<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>

<script>
  var backgroundnum = 5;
  var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));

  $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
</script>




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
<a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
<a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<script>
var option = {
  engineKey: '990f4c9c13b06ab1d082'
};
(function(w,d,t,u,n,s,e){
   s = d.createElement(t);
   s.src = u;
   s.async = 1;
   w[n] = function(r){
     w[n].opts = r;
   };
   e = d.getElementsByTagName(t)[0];
   e.parentNode.insertBefore(s, e);
})(window,document,'script','//tinysou-cdn.b0.upaiyun.com/ts.js','_ts');
</script>
  </div>
</body>
</html>